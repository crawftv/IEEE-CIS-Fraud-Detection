{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/ieee-fraud-detection/leaderboard#score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 433)\n",
      "(506691, 432)\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_transaction = pd.read_csv('data/train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('data/test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "train_identity = pd.read_csv('data/train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('data/test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "# Drop target, fill in NaNs\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "X_train = X_train.fillna(-999)\n",
    "X_test = X_test.fillna(-999)\n",
    "\n",
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        X_test[f] = lbl.transform(list(X_test[f].values))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "split data frames into transactions with identity and transactions without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - t.isFraud.sum()/590540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample.isFraud = np.ones((sample.isFraud.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample.to_csv(\"majority_class.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "majority baseline scored 50% on the kaggle board. I was hoping it would be imbalanced and easier to score high. oh well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stupid XGBoost \n",
    "- just seeing what happens\n",
    "- inspired by this https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    missing=-999,\n",
    "    random_state=2019,\n",
    "    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CrawtoML:\n",
    "    def __init__(self, data, target,id_column=None):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.id_column = id_column\n",
    "        self.features = self.get_features()\n",
    "        self.numeric_columns = self.numerics()\n",
    "        self.other_types = self.other_types()\n",
    "        self.nan_free = self.nan_free()\n",
    "\n",
    "    def get_features(self):\n",
    "        a = list(t.columns.values)\n",
    "        a.remove(self.target)\n",
    "        if self.id_column is not None:\n",
    "            a.remove(self.id_column)\n",
    "        return a\n",
    "\n",
    "    def numerics(self):\n",
    "        numerics = []\n",
    "        for i in self.features:\n",
    "            if self.data[i].dtypes in [\"int64\", \"float64\"]:\n",
    "                numerics.append(i)\n",
    "        self.numeric_columns = numerics\n",
    "        return self.numeric_columns\n",
    "\n",
    "    def other_types(self):\n",
    "        others = [i for i in self.features if i not in self.numeric_columns]\n",
    "        self.other_types = others\n",
    "        return self.other_types\n",
    "\n",
    "    def nan_free(self):\n",
    "        s = self.data[self.features].isna().sum()\n",
    "        z = list(zip(s.index, s.values))\n",
    "        return [i for i, j in z if j == 0]\n",
    "\n",
    "    def nan_chart(self):\n",
    "        p = (self.data[self.features].isna().sum().sort_values() / len(self.data)).plot(\n",
    "            title=\"NAN as a % of all values\", xticks=[]\n",
    "        )\n",
    "        p.set_yticklabels(['{:,.2%}'.format(x) for x in p.get_yticks()])\n",
    "        \n",
    "\n",
    "    def correlation_report(self):\n",
    "        seaborn.heatmap(self.data[self.numeric_columns].corr())\n",
    "\n",
    "    def distribution_report(self):\n",
    "        self.distribution_r()\n",
    "        print(seaborn.distplot(self.data[self.target]))\n",
    "        print(\n",
    "            seaborn.PairGrid(self.data, x_vars=self.features, y_vars=self.target).map(\n",
    "                seaborn.scatterplot\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def distribution_r(self):\n",
    "        import pandas\n",
    "\n",
    "        print(\n",
    "            pandas.DataFrame(\n",
    "                [\n",
    "                    self.distribution_fit(self.data, i)\n",
    "                    for i in self.numeric_columns + [self.target]\n",
    "                ],\n",
    "                index=self.numeric_columns + [self.target],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def distribution_fit(self,columns):\n",
    "        from scipy.stats import shapiro\n",
    "\n",
    "        \"\"\"\n",
    "        x is a column_name\n",
    "        \"\"\"\n",
    "        shapiro_values = shapiro(self.data[columns])\n",
    "        test_indication = True if shapiro_values[1] > 0.05 else False\n",
    "\n",
    "        distribution_types = [\"norm\", \"expon\", \"logistic\", \"gumbel\"]\n",
    "        # anderson_values = anderson(automl.data[numeric_column], dist=i)\n",
    "\n",
    "        return {\n",
    "            \"Shapiro-Wilks_Test_Statistic\": shapiro_values[0],\n",
    "            \"Shapiro-Wilks_p_Value\": shapiro_values[1],\n",
    "            \"Normal distribution ?\": test_indication\n",
    "            # \"Anderson_Darling_Test_Statistic_Normal\": anderson_values[0][0],\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Target Column: %s \\n \\\n",
    "            Feature columns: %s\\n \\\n",
    "            Numeric Columns: %s\"(\n",
    "            self.target, self.features, self.numeric_columns\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CrawtoML(data=t,target=\"isFraud\",id_column=\"TransactionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.data[c.nan_free]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.distribution_fit(c.nan_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
